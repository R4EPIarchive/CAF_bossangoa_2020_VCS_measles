---
title: "Bossangoa Vaccination survey"
output:
  html_document:
    df_print: paged
  word_document:
    keep_md: yes
---



# Introduction to this template

This is a template which can be used to create a report from a vaccination 
coverage survey. 

- There are sections for reading and cleaning data, followed by 
    weighting calculations and then survey analysis.  
- For a more detailed explanation of this template, please visit https://r4epis.netlify.com/surveys  
- Feedback and suggestions are welcome at the [GitHub issues page](https://github.com/R4EPI/sitrep/issues)

- Text within <! > will not show in your final document. These comments are used
to explain the template. You can delete them if you want.

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This comment will not show up when you knit the document.
A comment with a title with slashes indicates a name of a code chunk.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->


## Installing and loading required packages 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// setup \\\
--------------------------------------------------------------------------------
Several packages are required for different aspects of  analysis with *R*. 
You will need to install these before starting. 
These packages can be quite large and may take a while to download in the
field. If you have access to a USB key with these packages, it makes sense to
copy and paste the packages into your computer's R package library 
(run the command .libPaths() to see the folder path). 
For help installing packages, please visit https://r4epis.netlify.com/welcome
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
  

```{r setup, include = FALSE, results='hide', message=FALSE, warning=FALSE}
## hide all code chunks in the output, but show errors
knitr::opts_chunk$set(echo = FALSE, error = TRUE, fig.width = 6*1.25, fig.height = 6)


## set default NA to - in output, define figure width/height
options(knitr.kable.NA = "-")



## Installing required packages for this template
required_packages <- c("knitr",       # create output docs
                       "here",        # find your files
                       "rio",         # for importing data
                       "epitrix",     # clean/shape data
                       "dplyr",       # clean/shape data
                       "tidyr",       # clean/shape data
                       "forcats",     # manipulate and rearrange factors
                       "stringr",     # manipulate texts
                       "ggplot2",     # create plots and charts
                       "sitrep",      # MSF field epi functions
                       "survey",      # for survey functions
                       "srvyr"        # dplyr wrapper for survey package
                       )

for (pkg in required_packages) {
  ## install packages if not already present
  if (!pkg %in% rownames(installed.packages())) {
    install.packages(pkg)
  }
  
  ## load packages to this current session 
  library(pkg, character.only = TRUE)
}


## set default text size to 18 for plots
## give classic black/white axes for plots
ggplot2::theme_set(theme_classic(base_size = 18))
```



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// read_Kobo_data \\\
--------------------------------------------------------------------------------
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r read_kobo_data, warning = FALSE, message = FALSE}

## Excel file ------------------------------------------------------------------
## Read in the household data
study_data_hh <- rio::import(here::here("9_data", 
                                        "raw",
                                        "VCS_Bossangoa_2020-07-16.xlsx"), 
                             which = "VCS_Bossangoa_VCS_2020") %>% 
  janitor::clean_names()

## Excel file
## Read in the individual data
study_data_indiv <- rio::import(here::here("9_data", 
                                        "raw",
                                        "VCS_Bossangoa_2020-07-16.xlsx"),
                                which = "r1")%>% 
  janitor::clean_names()


```



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// merge_data_levels \\\
--------------------------------------------------------------------------------
For survey datasets with two levels (e.g. household and individual), 
these levels will need to be merged in to one dataset. 

This is done using a unique identifier for the household 
(which has to be repeated for each row in the individuals dataset) 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->


```{r merge_data_levels}

## join the individual and household data to form a complete data set
 study_data_raw <- left_join(study_data_hh, 
                             study_data_indiv, 
                             by = c("id" = "submission_id"))
```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// Remove training data and empty columns \\\
--------------------------------------------------------------------------------
This section will remove any training data and also any unused columns
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->


```{r remove_training_empty_cols}

## Remove training data and empty cols
study_data_cleaned <- study_data_raw %>% 
  # need to convert today to a date to be able to filter on it
  mutate(today = as.Date(today, format = "%Y-%m-%d"))  %>% 
  # filter out data before the 6th of July
  filter(today >= "2020-07-06") %>% 
  # Remove empty columns
  janitor::remove_empty("cols")

```






<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// read_population_data \\\
--------------------------------------------------------------------------------
This template uses population data to create survey weights. 

There are three options:
- You can read in a spreadsheet with age group, sex and region data.
- You can put in the specific populations into the gen_population function. 
- If you have the total or regional populations, you can estimate the age group
from proportions.

Below we show basic examples for reading data and entering counts - as well as 
a more complex version using proportions to get the age/sex breakdown in 
two seperate regions. (Useful if doing a stratified survey)

Comment out the options you are not using.

Make sure that the groups fit those in your survey data!

Age group proportions are from the OCBA population denominators tool v1. The
proportions below are for sub-Saharan Africa in 2019. They are only an estimate!
If you have more specific proportions, you can use them below.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r read_population_data, warning = FALSE, message = FALSE}


## Read data -------------------------------------------------------------------

## This step reads in your population data from Excel.
## You may need to rename your columns.

# population_data <- rio::import(here::here("population.xlsx"), which = "Sheet1")

## repeat preparation steps as appropriate


## Enter counts directly -------------------------------------------------------


## Below is an example of how to enter population counts by groups. 

# population_data_age <- gen_population(
#   groups = c("0-2", "3-14", "15-29", "30-44", "45+"),
#   counts = c(3600, 18110, 13600, 8080, 6600),
#   strata = NULL) %>%
#   rename(age_group = groups,
#     population = n)


## Create counts from proportions ----------------------------------------------
## This step helps you estimate sub-group size with proportions.
## You need to replace the total_pop and proportions. You can change the groups
## to fit your needs. 

## Here we repeat the steps for two regions (district A and B) then bind the two
## together 


## generate population data by age groups in years for district A
# population_data_age_district_a <- gen_population(total_pop = 10000, # set total population 
#   groups      = c("0", "1", "2", "3", "4", "5+"), # set groups
#   proportions = c(0.0164, 0.0164, 0.015, 0.015,
#                   0.015, 0.1386), # set proportions for each group
#   strata      = c("Male", "Female")) %>%           # stratify by gender
#   rename(age_group  = groups,                      # rename columns (NEW NAME = OLD NAME)
#          sex        = strata,
#          population = n) %>% 
#   mutate(health_district = "District A")           # add a column to identify region 


## generate population data by age groups in years for district B
# population_data_age_district_b <- gen_population(total_pop = 10000, # set total population 
#   groups      = c("0", "1", "2", "3", "4", "5+"), # set groups
#   proportions = c(0.0164, 0.0164, 0.015, 0.015,
#                   0.015, 0.1386), # set proportions for each group
#   strata      = c("Male", "Female")) %>%           # stratify by gender
#   rename(age_group  = groups,                      # rename columns (NEW NAME = OLD NAME)
#          sex        = strata,
#          population = n) %>% 
#   mutate(health_district = "District B")           # add a column to identify region 



## bind region population data together to get overall population 
# population_data_age <- bind_rows(population_data_age_district_a, 
#                                  population_data_age_district_b)
```




<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// cluster_counts \\\
--------------------------------------------------------------------------------
For cluster surveys you may want to add survey weights at the cluster level. 

This could be done as in the read_population_data chunk. 

Alternatively if there are only a few counts, these could be entered as below
in to a tibble. 

In any case you will need to have one column with a cluster identifier which 
matches your survey data, and another column with the number of households in 
each cluster. 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r cluster_counts}

# created cluster spreadsheet indicated cluster IDs (all village names), cluster (village) populations, and number of total households in each cluster (village). Last one based on average household size from protocol. 

#read cluster data in
cluster_counts <- rio::import(here::here("9_data", 
                                         "raw", 
                                         "cluster_counts.xlsx")) %>%
  ## save variables as lower case
  janitor::clean_names()


## Clean cluster data
cluster_counts <- cluster_counts %>% 
  ## Round up to one decimal place the total HH number
  mutate(total_hh = round(total_hh, digits = 0)) %>% 
  ## convert all village_names to lower case
  mutate(village_name = tolower(village_name)) %>% 
  ## add an underscore where there are any empty spaces between words
  mutate(village_name = str_replace_all(village_name, " ", "_")) %>% 
  ## replace the - with _ in village name
  mutate(village_name = str_replace_all(village_name, "-", "_")) %>% 
  ## remove special characters on o
  mutate(village_name = str_replace_all(village_name, "ô","o")) %>% 
  ## remove special characters on u
  mutate(village_name = str_replace_all(village_name, "û","u"))


## Select only the household numbers and convert to tibble
cluster_counts <- cluster_counts %>% 
  ## remove the population variable
  select(-pop) %>% 
  ## convert to tibble/type of dataframe
  as_tibble()


```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// browse_data \\\
--------------------------------------------------------------------------------

You'll want to look at your data. Here are a few ways you can explore.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r browse_data, eval = FALSE}
## view the first ten rows of data
head(study_data_cleaned, n = 10)

## view your whole dataset interactivley (in an excel style format)
View(study_data_cleaned)

## overview of variable types and contents
str(study_data_cleaned)

## get summary: 
## mean, median and max values of variables
## counts for categorical variables
## also gives number of NAs
summary(study_data_cleaned)

## view unique values contained in variables 
## you can run this for any column -- just replace the column name
unique(study_data_cleaned$sex)


```






<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This part of the script will create and clean variables in your data.

All your cleaning and variable creation should happen in these chunks.
That way, in case something goes wrong, you can push the small arrow at the top
of the chunk to re-run all the code chunks up to the current one.

The chunks are:
- standardise_dates  -- will set up and clean dates.
- create_age_group   -- creates the age group variables from age
- factor_vars        -- helps clean factor variables
- cluster_household_other    -- fix cluster_household numbering problems and other issues
- remove_unused_data -- dropping unused rows/columns
- survey_weights     -- claculating survey weights according to study design
- survey_design      -- create a survey object for weighted analysis 

You must adapt this section according to your data!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// standardise_dates \\\
--------------------------------------------------------------------------------

This chunk will help you set up and clean your date variables.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r standardise_dates}

## Non-DHARMA data -------------------------------------------------------------
## Use this section if you did not have Dharma data. 

## use the guess_dates() function to make a first pass at date variables.
# study_data_cleaned <- study_data_cleaned %>%
#   mutate_at(vars(matches("date|Date")), linelist::guess_dates,
#             error_tolerance = 0.5)


## Fix wrong dates ------------------------------------------------------------- 

## Some dates will be unrealistic or wrong.
## Here is an example of how to manually fix dates. 
## Look at your data and edit as needed.

## set specific unrealistic dates to NA
# study_data_cleaned <- mutate(study_data_cleaned,
#                            date_of_onset < as.Date("2017-11-01") ~ as.Date(NA), 
#                            date_of_onset == as.Date("2081-01-01") ~ as.Date("2018-01-01"))

```




<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// create_age_group \\\ 
--------------------------------------------------------------------------------

This chunk will help you set up your age group variable.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r create_age_group}

## Age group variables ----------------------------------------------------------
## This step shows you how to create categorical variables from numeric variables.
## We have some intermediate steps on the way.

## make sure age is an integer 
study_data_cleaned <- study_data_cleaned %>% 
  mutate(age_years = as.integer(age_years), 
         age_months = as.integer(age_months))

## create an age group variable with 3 age groups 6-11months, 1-4 years, 5-9 years
study_data_cleaned <- study_data_cleaned %>%
  mutate(age_group = factor(case_when(
      age_months >= 6 & age_months <= 11 ~ "6-11 mths",
      age_years >=1 & age_years < 5  ~ "1-4 yrs",
      age_years >= 5 ~ "5-9 yrs",
      TRUE ~ NA_character_
    ),
  levels = c("6-11 mths", "1-4 yrs", "5-9 yrs"))
  )

```




<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// factor_vars \\\
--------------------------------------------------------------------------------

This chunk will help you clean factor variables.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r factor_vars}

## create a new variable by reordering the levels of a factor 
# study_data_cleaned <- study_data_cleaned %>%
#   mutate(no_consent = fct_relevel(q65_consent_no_reason,
#                                   "Refuse to explain", 
#                                   "No time", 
#                                   "Bad experience",
#                                   "Other reason")
#         )


## MSF vaccination - combine yes answers into one - yes card and yes verbal
study_data_cleaned <- study_data_cleaned %>% 
  mutate(msf_vacc_status = case_when(
    is.na(msf_vacc) ~ NA_character_,
    msf_vacc == "card" ~ "Yes", 
    msf_vacc == "verbal" ~ "Yes", 
    msf_vacc == "no" ~ "No", 
    msf_vacc == "dont_know" ~ "Don't know", 
    msf_vacc == "no_answer" ~ "No answer"))

#checking the variable we created above. 
#table(study_data_cleaned$msf_vacc) # old variable
#table(study_data_cleaned$msf_vacc_status) # new variable


## ROUTINE vaccination - combine yes answers into one - yes card and yes verbal
study_data_cleaned <- study_data_cleaned %>% 
  mutate(routine_vacc_status = case_when(
    is.na(routine_vacc) ~ NA_character_,
    routine_vacc == "card" ~ "Yes", 
    routine_vacc == "verbal" ~ "Yes", 
    routine_vacc == "no" ~ "No", 
    routine_vacc == "dont_know" ~ "Don't know", 
    routine_vacc == "no_answer" ~ "No answer"))

# checking the variable we created above.
#table(study_data_cleaned$routine_vacc) # old variable
#table(study_data_cleaned$routine_vacc_status) # new variable


# ## combine all vaccine variables in to one 
# ## keep the yes answers and change others to no 
# ## if missing in all three vars then stays NA
study_data_cleaned <- study_data_cleaned %>%
  mutate(vaccination_status = case_when(
    is.na(msf_vacc) &
    is.na(routine_vacc) ~ NA_character_,
    msf_vacc    == "card" ~ "Card",
    routine_vacc == "card" ~ "Card",
    msf_vacc    == "verbal" ~ "Verbal",
    routine_vacc == "verbal"  ~ "Verbal",
    TRUE      ~ "Unvaccinated"
    )
  )

# ## correct the order of levels in newly created var
study_data_cleaned <- study_data_cleaned %>%
  mutate(vaccination_status = fct_relevel(vaccination_status,
                                          "Card",
                                          "Verbal",
                                          "Unvaccinated")
  )

## create a new grouping for vaccine status variable 
## simplified, card or verbal then yes otherwise no 
study_data_cleaned <- study_data_cleaned %>%
  mutate(
    vaccination_status_simple = case_when(
      is.na(vaccination_status)                   ~ NA_character_,
      vaccination_status %in% c("Card", "Verbal") ~ "Vaccinated",
      TRUE                                        ~ "Unvaccinated")
    )
# 
# ## correct the order of levels in newly created var
study_data_cleaned <- study_data_cleaned %>%
  mutate(vaccination_status_simple = fct_relevel(vaccination_status_simple,
                                                 "Vaccinated",
                                                 "Unvaccinated")
  )
# 
# ## explicitly replace NA of a factor
# study_data_cleaned <- study_data_cleaned %>%
#   mutate(vaccine_routine = fct_explicit_na(vaccine_routine, na_level = "No answer"))


```

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// cluster/village_correction \\\
--------------------------------------------------------------------------------

Your data might have incorrectly entered cluster/village/team combinations.
This will be need to be corrected prior to adding the weights. 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

**This section will need to be re-checked with the final dataset**


```{r cluster_correction}

## First need to convert cluster_number into an integer
study_data_cleaned <- study_data_cleaned %>% 
  mutate(cluster_number = as.integer(cluster_number))


## Check cluster numbers always match the village and team
study_data_cleaned %>% 
  group_by(team_number, cluster_number) %>% 
  ## identify unique village names by cluster number
  distinct(village_name) %>% 
  ## arrange cluster numbers in numerical order
  arrange(cluster_number)


## We identify that there are two village names for cluster 20
## Confirm which is the correct cluster number
cluster_check <- study_data_cleaned %>% 
  filter(team_number == 5, cluster_number == 20)

## We confirm that the error is with bobere, as in all other instances for cluster 20, bokato_1 is the village name

## Correct the bokato_1 village_name
study_data_cleaned <- study_data_cleaned %>% 
  mutate(village_name = case_when(
    team_number == 5 & cluster_number == 20 ~ "bokato_1",
    TRUE ~ village_name
  ))


## Additional cleaning step of village names to match names in the cluster count
## As village names were repeated in the communes, we need to ensure that all village names are unique for the survey weight part
study_data_cleaned <- study_data_cleaned %>% 
  mutate(village_name = case_when(
    village_name == "bogbolo" ~ "benzambe_bogbolo",
    TRUE ~ village_name
  ))


## Convert children_number to an integer
study_data_cleaned <- study_data_cleaned %>% 
  mutate(children_count = as.numeric(children_count))


## Convert household_number to an integer
study_data_cleaned <- study_data_cleaned %>% 
  mutate(household_number = as.numeric(household_number))

```



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// Clean household numbers \\\
--------------------------------------------------------------------------------

If any errors in household number were identified through browsing data, then they need to be fixed prior to adding the weights as 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

**This will need to be re-checked with the full dataset** 

```{r clean_household_numbers}

## Need to identify which household numbers have been accidentally repeated and fix them
dup_hh <- study_data_cleaned %>% 
  # remove empty households as they may have the same household number but no data
  filter(empty_household == "no") %>% 
  ## look for unique combination of cluster, household number and id
  distinct(cluster_number, household_number, id) %>% 
  ## sort by cluster and household number
  arrange(cluster_number, household_number) %>% 
  ## Identify duplicated combination of cluster number and household number
  janitor::get_dupes(cluster_number, household_number)


# ## we find two duplicates household cluster combinations
# ## Need to review cluster 25
 study_data_cleaned %>% 
   filter(cluster_number == 25)

## Rename 2nd/later household number 3 as household number 10
## Rename 2nd/later household number 8 as household number 11 
study_data_cleaned <- study_data_cleaned %>% 
  mutate(household_number = case_when(
    household_number == 3 & id == 417429 ~ 10,
    household_number == 8 & id == 417424 ~ 11,
    TRUE ~ household_number
  ))


```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// remove_unused_data \\\
--------------------------------------------------------------------------------

Your data might have empty rows or columns you want to remove.
You can also use this section to create temporary datasets so you can review
specific variables or rows.

You may want to drop rows with missing IDs (i.e. blank rows from excel) 
simply add a !is.na(fact_0_id) if using a dharma dataset.

Those without consent need to be dropped too

It is important that you drop observations before adding survey weights!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r remove_unused_data}
## Drop unused rows  -----------------------------------------------------------

## store the cases that you drop so you can describe them (e.g. non-consenting, empty households and households with no children in the age range)
dropped <- study_data_cleaned %>% 
  filter(consent == "no" | 
           empty_household == "yes" |
           children_count == 0 |
           is.na(children_count))


## drop the unused rows from the survey data set  
study_data_cleaned <- study_data_cleaned %>%
  ## This will remove empty households or households where head said no
  filter(consent == "yes")

```




<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// survey_weights \\\
--------------------------------------------------------------------------------

Create survey weights according to your study design. 

These require information on the source population and/or the clusters surveyed. 

There are three options, comment out those you do not use: 
- Stratified 
- Cluster 
- Stratified and cluster 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r survey_weights}

## cluster ---------------------------------------------------------------------

## merge village and household to create a unique household ID 
study_data_cleaned <- study_data_cleaned %>% 
  mutate(hh_id = str_glue("{village_name}_{household_number}"))


## create cluster weights 
study_data_cleaned <- add_weights_cluster(x = study_data_cleaned, 
                                          cl = cluster_counts, 
                                          eligible = children_count, 
                                          interviewed = children_count, 
                                          cluster_x = village_name, 
                                          cluster_cl = village_name, 
                                          household_x = household_number, 
                                          household_cl = total_hh, 
                                          surv_weight = "surv_weight_cluster", 
                                          surv_weight_ID = "surv_weight_ID_cluster", 
                                          ignore_cluster = FALSE, 
                                          ignore_household = FALSE)

```



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// survey_design \\\
--------------------------------------------------------------------------------

Create survey object according to your study design. 

Used the same way as dataframes to calculate weight proportions etc. 

Make sure that all necessary variables are created before this. 

There are four options, comment out those you do not use: 
- Simple random 
- Stratified 
- Cluster 
- Stratified cluster

For this template - we will pretend that we cluster surveys in two seperate 
strata (health districts A and B). 
So to get overall estimates we need have combined cluster and strata weights. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r survey_design}


## cluster ---------------------------------------------------------------------

survey_design_cluster <- study_data_cleaned %>% 
  as_survey_design(ids = village_name, # 1 for no cluster ids 
                   weights = surv_weight_cluster, # weight variable created above 
                   strata = NULL # sampling was simple (no strata)
                  )


```



<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// save_cleaned_data \\\
--------------------------------------------------------------------------------

You can save your cleaned dataset as an Excel. 
This automatically names your file "study_data_cleaned_DATE", where DATE is the
current date.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r save_cleaned_data}
rio::export(study_data_cleaned, 
            file = here::here("9_data", "clean", str_glue("study_data_cleaned_{Sys.Date()}.xlsx")))

```



# Results

## Survey inclusion 

<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// inclusion_counts \\\
--------------------------------------------------------------------------------

The below chunks calculate values that are displayed with the inline text

Get the counts of clusters and households included 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

```{r inclusion_counts}

## get counts of number of clusters 
num_clus <- study_data_cleaned %>%
  ## trim data to unique clusters
  distinct(cluster_number) %>% 
  ## get number of rows (count how many unique)
  nrow()

## get counts of number households 
num_hh <- study_data_cleaned %>% 
  ## get unique houses by cluster
  distinct(cluster_number, household_number) %>% 
  ## get number of rounds (count how many unique)
  nrow()

```


We included `r num_hh` households accross `r num_clus` clusters in this survey analysis. 


Among the `r nrow(dropped)` individuals without consent to participate in the survey, 
the reasons for refusal are described below. 

<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// consent_reasons \\\
--------------------------------------------------------------------------------

This chunk will create a table of dropped individuals by reason for no consent. 

Note that these reasons are spread over multiple columns, thus the proportion
needs to be of the total and missings need to be dropped. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

**This section could be run if there are some refusals in the dataset**

```{r consent_reasons}

## using the dataset with dropped individuals 
# tab_linelist(dropped, "no_consent_reason", col_total = TRUE, digits = 1) %>% 
#   ## drop variable column and rename others
#   select("Reason" = value, 
#          "n" = n, 
#          "%" = proportion) %>%
#   kable(digits = 1)
```



<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// cluster_hh_size \\\
--------------------------------------------------------------------------------

The below chunks calculate values that are displayed with the inline text

Get counts of households per cluster and individuals per household. 
From these create medians and standard deviations. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

```{r cluster_hh_size}

## get counts of the number of households per cluster
clustersize <- study_data_cleaned %>% 
  ## trim data to only unique households within each cluster
  distinct(cluster_number, household_number) %>%
  ## count the number of households within each cluster
  count(cluster_number) %>% 
  pull(n)

## get the median number of households per cluster
clustermed <- median(clustersize)

## get the min and max number of households per cluster
## paste these together seperated by a dash 
clusterrange <- str_c(range(clustersize), collapse = "--")

## get counts of children per household 
## do this by cluster as household IDs are only unique within clusters
hhsize <- study_data_cleaned %>% 
  count(cluster_number, household_number) %>%
  pull(n) 

## get median number of children per household
hhmed <- median(hhsize)
## get the min and max number of children per household
## paste these together seperated by a dash 
hhrange <- str_c(range(hhsize), collapse = "--")

# get standard deviation 
hhsd <- round(sd(hhsize), digits = 1)
```


The median number of households per cluster was
`r clustermed`, with a range of `r clusterrange`. The median number of children
per household was `r hhmed` (range: `r hhrange`, standard deviation: `r hhsd`). 


## Demographic information


In total we included `r nrow(study_data_cleaned)` in the survey analysis. 
The age break down and a comparison with the source population is shown below. 


<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// descriptive_sampling_bias \\\
--------------------------------------------------------------------------------

Compare the proportions in each age group between your sample and 
the source population. 

This is important to be able to highlight potential sampling bias. 
You could similarly repeat this looking at distributions by sex. 

Note that these p-values are just indicative, and a descriptive discussion (or
visualisation with age-pyramids below) of the distributions in your study sample 
compared to the source population is more
important that the binomial test itself. This is because increasing sample size
will more often than not lead to differences that may be irrelevant after weighting
your data. 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

```{r descriptive_sampling_bias, warning = FALSE}
## counts and props of the study population
ag <- tab_linelist(study_data_cleaned, "age_group") %>%
  mutate(n_total = sum(n)) %>%
  select(-variable) %>%
  rename(age_group = value) %>%
  mutate(age_group = fct_inorder(age_group))

## counts and props of the source population
# propcount <- group_by(population_data_age, age_group) %>%
#     tally(population) %>%
#     mutate(proportion = n / sum(n))

## bind together the columns of two tables, group by age, and perform a 
## binomial test to see if n/total is significantly different from population
## proportion.
  ## suffix here adds to text to the end of columns in each of the two datasets
# left_join(ag, propcount, by = "age_group", suffix = c("", "_pop")) %>%
#   group_by(age_group) %>%
# 
#   ## broom::tidy(binom.test()) makes a data frame out of the binomial test and
#   ## will add the variables p.value, parameter, conf.low, conf.high, method, and
#   ## alternative. We will only use p.value here. You can include other
#   ## columns if you want to report confidence intervals
#   mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%
#   unnest(cols = c(binom)) %>% # important for expanding the binom.test data frame
#   mutate(proportion_pop = proportion_pop * 100) %>%
# 
#   ## Adjusting the p-values to correct for false positives 
#   ## (because testing multiple age groups). This will only make 
#   ## a difference if you have many age categories
#   mutate(p.value = p.adjust(p.value, method = "holm")) %>%
#   select(age_group, n, proportion, n_pop, proportion_pop, p.value) %>%
#                       
#   ## Only show p-values over 0.001 (those under report as <0.001)
#   mutate(p.value = ifelse(p.value < 0.001, "<0.001", as.character(round(p.value, 3)))) %>%
# 
#   ## rename the columns appropriatley
#   rename(
#     "Age group" = age_group,
#     "Study population (n)" = n,
#     "%" = proportion,
#     "Source population (n)" = n_pop,
#     "%" = proportion_pop,
#     "P-value" = p.value
#   ) %>%
#   kable(digits = 1)

```



<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// median_age_sex_ratios \\\
--------------------------------------------------------------------------------

The below chunk calculate values that are displayed inline

This returns the median age and sex ratios overall as well as by age group. 
It also pulls the age group with the highest sex ratio. 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

```{r median_age_sex_ratios}
## compute the median age 
medage <- median(study_data_cleaned$age_years)
## paste the lower and uper quartile together
iqr <- str_c(  # basically copy paste togehter the following
  ## calculate the 25% and 75% of distribution, with missings removed
  quantile(     
    study_data_cleaned$age_years, 
    c(0.25, 0.75), 
    na.rm = TRUE), 
  ## between lower and upper place an en-dash
  collapse = "--")


## compute overall sex ratio 
sex_ratio <- study_data_cleaned %>% 
  count(sex) %>% 
  pivot_wider(names_from = sex, values_from = n) %>% 
  mutate(ratio = round(male/female, digits = 3)) %>%
  pull(ratio)

## compute sex ratios by age group 
sex_ratio_age <- study_data_cleaned %>% 
  count(age_group, sex) %>% 
  pivot_wider(names_from = sex, values_from = n) %>% 
  mutate(ratio = round(male/female, digits = 3)) %>%
  select(age_group, ratio)

## sort table by ascending ratio then select the lowest (first)
min_sex_ratio_age <- arrange(sex_ratio_age, ratio) %>% slice(1)
```

Among the `r nrow(study_data_cleaned)` surveyed individuals, there were 
`r fmt_count(study_data_cleaned, sex == "female")` females and 
`r fmt_count(study_data_cleaned, sex == "male")` males (unweighted). The male to
female ratio was `r sex_ratio` in the surveyed population. The lowest male to
female ratio was `r min_sex_ratio_age$ratio`
in the `r min_sex_ratio_age$age_group` year age group.
The median age of surveyed individuals was `r medage` years (Q1-Q3 of `r iqr`
years). Children under five years of age made up 
`r fmt_count(study_data_cleaned, age_years < 5)`of the surveyed individuals.
The highest number of surveyed indivduals (unweighted) were in the 
`r table(study_data_cleaned$age_group) %>% which.max() %>% names()`
year age group.

Unweighted age distribution of population by year age group and gender.

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// describe_by_age_group_and_sex \\\
--------------------------------------------------------------------------------

This chunk will create an unweighted table of survey individuals by age group 
and sex.

Note that proportions are of the total sample (not within each gender) 
to change this, set proptotal = FALSE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r describe_by_age_group_and_sex}

tab_linelist(study_data_cleaned, age_group, 
             strata     = sex, 
             row_total  = TRUE,
             col_total  = TRUE,
             prop_total = TRUE) %>%
  ## select and rename column names appropriately
  select("Age"              = "value",
         "Female cases (n)" = "female n",
         "Female %"         = "female proportion",
         "Male cases (n)"   = "male n",
         "Male %"           = "male proportion",
         "Total") %>%
  kable(digits = 1)
```


There were `r fmt_count(study_data_cleaned, is.na(sex))` cases missing information on sex and 
`r fmt_count(study_data_cleaned, is.na(age_group))` missing age group.

Unweighted age and gender distribution of household population covered by the survey.
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// age_pyramid \\\
--------------------------------------------------------------------------------

This chunk creates an unweighted (using study_data_cleaned) age/sex pyramid
of your cases.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r age_pyramid, warning=FALSE}

plot_age_pyramid(study_data_cleaned, 
                 age_group = "age_group", 
                 split_by = "sex",
                 proportion = TRUE) + 
  labs(y = "Proportion", x = "Age group (years)") + # change axis labels
  theme(legend.position = "bottom",     # move legend to bottom
        legend.title = element_blank(), # remove title
        text = element_text(size = 18)  # change text size
       )
```

Weighted age and gender distribution of household population covered by the survey.  

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// age_pyramid_survey \\\
--------------------------------------------------------------------------------

This chunk creates a weighted (using survey_design) age/sex pyramid
of your cases.

Note - if this is substantially different to your unweighted 
pyramid, then it may suggest some sampling bias (similarly to the table comparing 
sample and source population distributions by binomial test). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r age_pyramid_survey, warning=FALSE}

plot_age_pyramid(survey_design_cluster,
                 age_group = "age_group",
                 split_by = "sex", 
                 proportion = TRUE) +
  labs(y = "Proportion", x = "Age group (years)") +                 # change axis labels
  theme(legend.position = "bottom",     # move legend to bottom
        legend.title = element_blank(), # remove title
        text = element_text(size = 18)  # change text size
       )
```



## Vaccination coverage

Weighted vaccination coverage; accepting equal validity from self-reported and 
card-reported vaccination status

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_overall \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while accpeting equal validity from self- and card-reporting. 

Note that this includes a design effect. 

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_overall}

survey_design_cluster %>%  # use the survey object (weighted)
  ## calculate weighted counts and weighted proportions
  tab_survey(vaccination_status_simple, deff = TRUE) %>% 
  ## select and rename appropriate columns 
  select("Vaccination status" = value, 
         "Children (n)" = n, 
         "% (95% CI)" = ci,
         "Design effect" = deff) %>% 
  kable(digits = 1)
```


Weighted vaccination coverage; distinguishing between vaccination cards and 
verbal confirmation 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_overall_detail \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while distinguishing validity from self- and card-reporting. 

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_overall_detail}

survey_design_cluster %>% # use the survey object (weighted)
  ## calculate weighted counts and weighted proportions
  tab_survey(vaccination_status) %>% 
  select("Vaccination status" = value, 
         "Children (n)" = n,  
         "% (95% CI)" = ci) %>% 
  kable(digits = 1)
```


Weighted vaccination coverage for MSF vaccination campaign: accepting equal validity from self-reported 
and card-reported vaccination status

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_MSF \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for the MSF vaccination campaign
coverage while not distinguishing validity from self- and card-reporting. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->


```{r vaccination_coverage_msf}

## coverage by card and verbal together

survey_design_cluster %>%  # use the survey object (weighted)
  ## calculate weighted counts and weighted proportions
  tab_survey(msf_vacc_status, deff = TRUE) %>%
  ## select and rename appropriate columns 
  select("MSF vaccination status" = value, 
         "Children (n)" = n, 
         "Vaccination coverage (95% CI)" = ci,
         "Design effect" = deff) %>%
  kable(digits = 1)


```



Weighted vaccination coverage for routine vaccination: accepting equal validity from self-reported 
and card-reported vaccination status

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_routine \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for routine vaccination
coverage while not distinguishing validity from self- and card-reporting. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->


```{r vaccination_coverage_routine}

## coverage by card and verbal together

survey_design_cluster %>%  # use the survey object (weighted)
  ## calculate weighted counts and weighted proportions
  tab_survey(routine_vacc_status, deff = TRUE) %>%
  ## select and rename appropriate columns 
  select("Routine vaccination status" = value, 
         "Children (n)" = n, 
         "Vaccination coverage (95% CI)" = ci,
         "Design effect" = deff) %>%
  kable(digits = 1)


```


Weighted vaccination coverage by sex; accepting equal validity from self-reported 
and card-reported vaccination status

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_sex \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while accpeting equal validity from self- and card-reporting; broken 
down by sex. 

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_sex}

survey_design_cluster %>% # use the survey object (weighted)
  ## calculate weighted counts and weighted proportions - stratified by sex
  tab_survey(vaccination_status_simple, strata = sex, deff = TRUE) %>%
  select(-variable) %>%
  rename("Vaccination status" = value) %>% 
  augment_redundant(" (n)"         = " n") %>%  # wrap all "n" in braces (note space before n)
  rename_redundant("% (95% CI)"    = " ci",      # relabel all columns containing "ci"
                   "Design Effect" = " deff") %>% # "deff" to "Design effect"
  kable(digits = 1)
```



Weighted vaccination coverage by sex; distinguishing between vaccination cards 
and verbal confirmation

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_sex_detail \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while distinguishing validity from self- and card-reporting; broken 
down by sex. 

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_sex_detail}
# return weighted counts and weighted proportions 
survey_design_cluster %>% 
  tab_survey(vaccination_status, strata = sex) %>%
  select(-variable) %>%
  rename("Vaccination status" = value) %>% 
  augment_redundant(" (n)"         = " n") %>%  # wrap all "n" in braces (note space before n)
  rename_redundant("% (95% CI)"    = " ci"      # relabel all columns containing "ci"
                   ) %>% 
  kable(digits = 1)
```



Weighted vaccination coverage by age group; accepting equal validity from self-reported and card-reported vaccination status

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_age_group \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while accpeting equal validity from self- and card-reporting; broken 
down by age group.  

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_age_group}
 
survey_design_cluster %>% 
  tab_survey(vaccination_status_simple, strata = age_group, deff = TRUE, 
             digits = 1, drop = "Missing", transpose = "value") %>%
  rename("Age group (years)" = age_group) %>% 
  augment_redundant(" (n)"         = " n") %>%  # wrap all "n" in braces (note space before n)
  rename_redundant("% (95% CI)"    = " ci",       # relabel all columns containing "ci"
                   "Design Effect" = " deff") %>% # "deff" to "Design effect"
  kable(digits = 1)
```

Weighted vaccination coverage by age group; distinguishing between vaccination 
cards and verbal confirmation 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vaccination_coverage_age_group_detail \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for vaccination 
coverage while distinguishing validity from self- and card-reporting; broken 
down by age group.  

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vaccination_coverage_age_group_detail}
 
survey_design_cluster %>% 
  tab_survey(vaccination_status, strata = age_group, 
             drop = "Missing", transpose = "value") %>%
  rename("Age group (years)" = age_group) %>% 
  augment_redundant(" (n)"         = " n") %>%  # wrap all "n" in braces (note space before n)
  rename_redundant("% (95% CI)"    = " ci"      # relabel all columns containing "ci"
  ) %>%
  kable(digits = 1)
```


## Reasons for not vaccinating

Weighted counts and proportions for reasons not vaccinated in routine and 
MSF campaign circumstances, individually, among those not vaccinated
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// no_vacc_reason_routine_campaign_combo \\\
--------------------------------------------------------------------------------

The below chunk creates a weighted table of counts proportions for reasons 
not vaccinated broken down by routine and campaign.  

This happens in three steps: 
- Counts and weighted proportions for routine
- Counts and weighted proportions for campaign 
- bind the columns together 

Note that low counts or short observation times may lead to a confidence interval 
that crosses zero (i.e. negative) for mortality ratios. These should be interpreted
as if no deaths or recoded to zero (impossible to have negative deaths). 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r no_vacc_reason_routine_campaign_combo}

## routine reasons 
routine <- survey_design_cluster %>% 
  ## filter for those not vaccinated 
  filter(routine_vacc %in% c("don't know", "no", "no_answer")) %>%
  tab_survey(reason_route_vacc) %>%
  # rename columns appropriately
  select("Reasons" = value, 
         "Routine (n)" = n , 
         "% (95% CI)" = ci)

## campaign reasons 
campaign <- survey_design_cluster %>% 
  ## filter for not vaccinated 
  filter(msf_vacc %in% c("don't know", "no", "no_answer")) %>%
  tab_survey(reason_msf_vacc) %>% 
  ## rename remaining columns appropriately 
  select("Reasons" = value,
         "Campaign (n)" = n, 
         "% (95% CI)" = ci)

## bind two together 
# bind_cols(routine, 
#           campaign) %>% 
#   kable(digits = 1)

```

## Proportion of children that previously had measles - overall

```{r previous_measles}

## Previous measles diagnosis
survey_design_cluster %>% 
  tab_survey(diagnosis_disease) %>% 
  ## rename remaining columns appropriately 
  select("Previous measles" = value,
         n, 
         "% (95% CI)" = ci)

```


`